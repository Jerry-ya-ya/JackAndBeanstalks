from flask import Blueprint, current_app
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime, timedelta
from .logic import fetch_and_store_news
import pytz
from flask import Flask
from models import ScheduleState, db

from .crawlerlogger import crawler_logger

last_run = None
next_run = None
scheduler = None
app = None

schedule_bp = Blueprint('schedule_bp', __name__)

def start_scheduler(flask_app: Flask):
    global next_run, scheduler, app
    app = flask_app # å°‡å¤–éƒ¨å‚³å…¥çš„ Flask æ‡‰ç”¨è¨­å®šçµ¦å…¨åŸŸè®Šæ•¸ appï¼Œè®“å…¶ä»–å‡½æ•¸èƒ½ç”¨å®ƒçš„ app_context
    if scheduler is None: # é¿å…é‡è¤‡å•Ÿå‹•æ’ç¨‹å™¨ï¼Œåªå•Ÿå‹•ä¸€æ¬¡ã€‚
        try:
            scheduler = BackgroundScheduler(timezone='Asia/Taipei') # è¨­å®šæ™‚å€ç‚ºå°åŒ—æ™‚é–“

            scheduler.add_job(
                scheduled_task,
                'interval',
                minutes=15,
                max_instances=15,  # é¿å…é‡ç–Š
                misfire_grace_time=30  # å…è¨±æœ€å¤šå»¶é² 30 ç§’
            )

            tz = pytz.timezone('Asia/Taipei')
            next_run = datetime.now(tz) + timedelta(minutes=15) #  è¨˜éŒ„ã€Œä¸‹ä¸€æ¬¡åŸ·è¡Œæ™‚é–“ã€è®Šæ•¸ï¼Œä¾›å‰ç«¯æŸ¥è©¢ç”¨

            scheduler.start()# å•Ÿå‹•æ’ç¨‹å™¨

            scheduled_task() # ç«‹å³åŸ·è¡Œä¸€æ¬¡ï¼Œå•Ÿå‹•å¾Œä¸ç”¨ç­‰ 15 åˆ†é˜
            crawler_logger.info("Scheduler started successfully")
        except Exception as e:
            crawler_logger.error(f"Error starting scheduler: {e}")

def scheduled_task():
    global last_run, next_run
    crawler_logger.info(f"ğŸŸ¡ scheduled_task è¢«å‘¼å« {datetime.now()}")
    try: # Flask çš„è³‡æ–™åº«æ“ä½œéœ€è¦æœ‰ã€Œæ‡‰ç”¨ä¸Šä¸‹æ–‡ã€ï¼Œé€™å¥æ˜¯å¿…è¦çš„åŒ…è£ï¼
        with app.app_context():
            start_time = datetime.now()
            added = fetch_and_store_news() # åŸ·è¡Œä½ è‡ªå®šç¾©çš„çˆ¬èŸ²é‚è¼¯ï¼Œä¸¦å›å‚³æ–°å¢äº†å¹¾ç­†è³‡æ–™
            end_time = datetime.now()
            crawler_logger.info(f"ğŸŸ¢ çˆ¬èŸ²æˆåŠŸæ–°å¢ {added} ç­†è³‡æ–™ï¼Œè€—æ™‚ {(end_time - start_time).total_seconds()} ç§’")

            tz = pytz.timezone('Asia/Taipei')
            now = datetime.now(tz)
            future = now + timedelta(minutes=15) # è¨˜éŒ„ä¸Šæ¬¡èˆ‡ä¸‹æ¬¡åŸ·è¡Œæ™‚é–“ï¼ˆçµ¦å‰ç«¯ info é¡¯ç¤ºï¼‰

            state = ScheduleState.query.filter_by(job_name="news_crawler").first()
            if state is not None:
                state.last_run = now
                state.next_run = future
                db.session.commit()
            else:
                crawler_logger.error("æ‰¾ä¸åˆ° news_crawler çš„ ScheduleState")
    except Exception as e:
        crawler_logger.error(f"ğŸ”´ çˆ¬èŸ²æ’ç¨‹éŒ¯èª¤: {e}")