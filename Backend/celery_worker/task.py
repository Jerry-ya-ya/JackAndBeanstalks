from . import celery
from .crawler.crawlerlogger import crawler_logger
from .crawler.logic import fetch_and_store_news  # ä½ çš„çˆ¬èŸ²æ ¸å¿ƒ
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from datetime import datetime, timedelta
import pytz
from models import db, ScheduleState

@celery.task
def hello():
    print("âœ… Celery Beat Task: Hello World æ¯åˆ†é˜åŸ·è¡Œä¸€æ¬¡ï¼")

@celery.task(bind=True, max_retries=3)
def scheduled_crawl_task(self):
    crawler_logger.info(f"ğŸŸ¡ Celery ä»»å‹™åŸ·è¡Œ {datetime.now()}")
    try:
        # å»¶é²å°å…¥ Flask app é¿å…å¾ªç’°å°å…¥
        from app import create_app
        app = create_app()
        
        with app.app_context():
            start_time = datetime.now()
            added = fetch_and_store_news()
            end_time = datetime.now()

            crawler_logger.info(f"ğŸŸ¢ çˆ¬èŸ²æ–°å¢ {added} ç­†è³‡æ–™ï¼Œè€—æ™‚ {(end_time - start_time).total_seconds()} ç§’")

            tz = pytz.timezone('Asia/Taipei')
            now = datetime.now(tz)
            future = now + timedelta(minutes=15)

            state = ScheduleState.query.filter_by(job_name="news_crawler").first()
            if state:
                state.last_run = now
                state.next_run = future
                db.session.commit()
            else:
                crawler_logger.error("æ‰¾ä¸åˆ° news_crawler çš„ ScheduleState")
    except Exception as e:
        crawler_logger.error(f"ğŸ”´ Celery ä»»å‹™éŒ¯èª¤: {e}")
        self.retry(exc=e, countdown=60)  # æœ‰éœ€è¦å¯ retry